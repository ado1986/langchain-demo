{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b97a7-67d2-4587-acba-48c804c63940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f24fc9e-edd8-4def-936a-edf773a42b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048337d7-5f3a-41be-8fac-7d8738cdb154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # chunk size (characters)\n",
    "    chunk_overlap = 200, # chunk overlap (characters)\n",
    "    add_start_index=True, # track index in original document\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49e6aea-919b-4ef1-a94e-cc4a5d4adf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# 改用通义千问dashboard SDK调用\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = os.getenv(\"API_KEY\")  # 通义千问密钥\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    model=\"text-embedding-v4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e861de35-4ea7-4d6e-944e-cc5f57220940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c2d42c91-c38e-4ac3-92c1-6a498f72869a', 'be8ff9cd-10a0-43e2-b743-f999db1f7683', '49eaca5c-c419-4e3d-977c-6cbc599f283b']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb89de5e-599c-4b99-8af3-97a65b603b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\") for doc in retrieved_docs\n",
    "    )\n",
    "\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474fb174-64a8-431c-a66d-e15a391e5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "## 修改timeout为30，前值为10。否则易造成请求超时。\n",
    "# 试试qwen3-max的结构化输出效果，模型qwen-max的效果不行\n",
    "model = init_chat_model(\"openai:qwen3-max\",\n",
    "                        temperature=0.5,\n",
    "                        timeout=30,\n",
    "                        max_tokens=1000,\n",
    "                        base_url=os.getenv('BASE_URL'),\n",
    "                        api_key=os.getenv('API_KEY'))\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36869ad7-0b85-4a08-bc40-c8e3805aea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_5902c87b401d40d2b46310d5)\n",
      " Call ID: call_5902c87b401d40d2b46310d5\n",
      "  Args:\n",
      "    query: standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}\n",
      "Content: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The standard method for Task Decomposition is **Chain of Thought (CoT)** prompting, as introduced by Wei et al. (2022). This technique instructs a model to \"think step by step,\" breaking down complex tasks into smaller, manageable subtasks to improve performance and provide insight into the model's reasoning process.\n",
      "\n",
      "Common extensions of this method include:\n",
      "\n",
      "1. **Tree of Thoughts (ToT)** (Yao et al., 2023):  \n",
      "   - Extends CoT by exploring multiple reasoning paths at each step, forming a tree structure.\n",
      "   - Uses search strategies like breadth-first search (BFS) or depth-first search (DFS).\n",
      "   - Each state in the tree is evaluated using a classifier (via prompting) or majority voting to guide the reasoning process.\n",
      "\n",
      "2. **LLM+P** (Liu et al., 2023):  \n",
      "   - Integrates an external classical planner for long-horizon planning.\n",
      "   - Leverages the Planning Domain Definition Language (PDDL) as an intermediate representation.\n",
      "   - The LLM translates the problem into PDDL format, a classical planner generates a plan, and the LLM converts it back into natural language.\n",
      "   - This approach outsources planning to specialized tools, which is particularly useful in domains like robotics where PDDL and planners are available.\n",
      "\n",
      "These extensions aim to enhance robustness, scalability, and effectiveness in handling complex, multi-step tasks beyond what standard CoT can achieve.\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a0d2f-7cf5-433b-89ae-91e0b9dc5b35",
   "metadata": {},
   "source": [
    "##### 另外一种方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59083b77-75ed-48f9-b706-6fa53138667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e691deb0-45fe-4a30-b648-4f4636251f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is task decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**Task decomposition** is the process of breaking down a complex or large task into smaller, more manageable subtasks or steps. This technique helps make difficult problems easier to solve by organizing them into a sequence or structure of simpler components that can be addressed individually.\n",
      "\n",
      "In the context of **AI agents and large language models (LLMs)**, task decomposition is a key part of planning. It enables the model to:\n",
      "\n",
      "- Understand the structure of a complex request,\n",
      "- Identify intermediate goals or subgoals,\n",
      "- Execute or reason about each part step by step.\n",
      "\n",
      "### Common Approaches to Task Decomposition:\n",
      "\n",
      "1. **Chain of Thought (CoT)**  \n",
      "   - Instructs the model to “think step by step.”\n",
      "   - Transforms a big task into a linear sequence of simpler reasoning steps.\n",
      "   - Enhances performance on complex tasks by leveraging more test-time computation.\n",
      "\n",
      "2. **Tree of Thoughts (ToT)**  \n",
      "   - Extends CoT by generating **multiple possible thoughts or actions at each step**, forming a tree-like structure.\n",
      "   - Uses search strategies like breadth-first search (BFS) or depth-first search (DFS).\n",
      "   - Each state (or partial solution) can be evaluated using a classifier or majority voting.\n",
      "\n",
      "3. **Prompting-Based Decomposition**  \n",
      "   - The LLM is prompted directly with instructions like:\n",
      "     - *\"Steps for XYZ.\\n1.\"*\n",
      "     - *\"What are the subgoals for achieving XYZ?\"*\n",
      "   - Can also use **task-specific prompts**, e.g., *\"Write a story outline.\"* for novel writing.\n",
      "\n",
      "4. **Human-in-the-Loop**  \n",
      "   - Subtasks are defined or refined with human input, ensuring accuracy or alignment with domain knowledge.\n",
      "\n",
      "5. **LLM + External Planner (LLM+P)**  \n",
      "   - Offloads planning to a classical AI planner using **PDDL (Planning Domain Definition Language)**.\n",
      "   - The LLM translates the natural language problem into PDDL, a planner generates a formal plan, and the LLM translates it back to natural language.\n",
      "   - Common in robotics but requires domain-specific PDDL models.\n",
      "\n",
      "### Why It Matters:\n",
      "Task decomposition allows AI systems to handle **long-horizon**, **multi-step**, or **interdisciplinary** problems—such as writing a research paper, planning a trip, or coordinating multimedia content generation—by structuring the work logically and sequentially.\n",
      "\n",
      "In systems like **HuggingGPT**, task decomposition is the first critical stage: the LLM acts as a “brain” that parses user input into a set of structured tasks with types, dependencies, and arguments, enabling coordinated execution across multiple AI models.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is task decomposition?\"\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
